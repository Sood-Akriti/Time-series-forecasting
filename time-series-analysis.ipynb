{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nfrom scipy import stats\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-16T08:05:46.296959Z","iopub.execute_input":"2023-09-16T08:05:46.297351Z","iopub.status.idle":"2023-09-16T08:05:46.308837Z","shell.execute_reply.started":"2023-09-16T08:05:46.297323Z","shell.execute_reply":"2023-09-16T08:05:46.307789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/sales-forecasting/train.csv\",index_col = 0)","metadata":{"execution":{"iopub.status.busy":"2023-09-16T04:43:08.984763Z","iopub.execute_input":"2023-09-16T04:43:08.985155Z","iopub.status.idle":"2023-09-16T04:43:09.051519Z","shell.execute_reply.started":"2023-09-16T04:43:08.985125Z","shell.execute_reply":"2023-09-16T04:43:09.050386Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-16T04:43:09.053840Z","iopub.execute_input":"2023-09-16T04:43:09.054217Z","iopub.status.idle":"2023-09-16T04:43:09.077448Z","shell.execute_reply.started":"2023-09-16T04:43:09.054186Z","shell.execute_reply":"2023-09-16T04:43:09.076252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.columns","metadata":{"execution":{"iopub.status.busy":"2023-09-16T04:43:09.078752Z","iopub.execute_input":"2023-09-16T04:43:09.079170Z","iopub.status.idle":"2023-09-16T04:43:09.091617Z","shell.execute_reply.started":"2023-09-16T04:43:09.079139Z","shell.execute_reply":"2023-09-16T04:43:09.090493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"execution":{"iopub.status.busy":"2023-09-16T04:43:09.092908Z","iopub.execute_input":"2023-09-16T04:43:09.093245Z","iopub.status.idle":"2023-09-16T04:43:09.107084Z","shell.execute_reply.started":"2023-09-16T04:43:09.093216Z","shell.execute_reply":"2023-09-16T04:43:09.105946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe()","metadata":{"execution":{"iopub.status.busy":"2023-09-16T04:46:50.602089Z","iopub.execute_input":"2023-09-16T04:46:50.602532Z","iopub.status.idle":"2023-09-16T04:46:50.625844Z","shell.execute_reply.started":"2023-09-16T04:46:50.602498Z","shell.execute_reply":"2023-09-16T04:46:50.624653Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2023-09-16T04:57:01.123943Z","iopub.execute_input":"2023-09-16T04:57:01.124313Z","iopub.status.idle":"2023-09-16T04:57:01.152318Z","shell.execute_reply.started":"2023-09-16T04:57:01.124285Z","shell.execute_reply":"2023-09-16T04:57:01.151238Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"null_values = df.isnull().sum()\nnull_values","metadata":{"execution":{"iopub.status.busy":"2023-09-16T05:01:52.074886Z","iopub.execute_input":"2023-09-16T05:01:52.075266Z","iopub.status.idle":"2023-09-16T05:01:52.100406Z","shell.execute_reply.started":"2023-09-16T05:01:52.075239Z","shell.execute_reply":"2023-09-16T05:01:52.099170Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"null_rows = df[df.isnull().any(axis=1)]\nnull_rows","metadata":{"execution":{"iopub.status.busy":"2023-09-16T05:02:34.900990Z","iopub.execute_input":"2023-09-16T05:02:34.901372Z","iopub.status.idle":"2023-09-16T05:02:34.945420Z","shell.execute_reply.started":"2023-09-16T05:02:34.901343Z","shell.execute_reply":"2023-09-16T05:02:34.944366Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['Postal Code'] = df['Postal Code'].fillna(5401)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-16T05:05:49.863666Z","iopub.execute_input":"2023-09-16T05:05:49.864064Z","iopub.status.idle":"2023-09-16T05:05:49.892199Z","shell.execute_reply.started":"2023-09-16T05:05:49.864033Z","shell.execute_reply":"2023-09-16T05:05:49.890766Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['Order Date'] = pd.to_datetime(df['Order Date'], format='%d/%m/%Y')\ndf['Ship Date'] = pd.to_datetime(df['Ship Date'], format='%d/%m/%Y')\ndf.sort_values('Order Date', ascending=True, inplace=True)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-16T05:07:49.140805Z","iopub.execute_input":"2023-09-16T05:07:49.141216Z","iopub.status.idle":"2023-09-16T05:07:49.196852Z","shell.execute_reply.started":"2023-09-16T05:07:49.141182Z","shell.execute_reply":"2023-09-16T05:07:49.195743Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"exclude_columns = [\"Customer Name\", \"City\", \"Order ID\", \"Customer ID\", \"Product ID\",\"Product Name\",\"Country\"]\ncolumn_names = [col for col in df.select_dtypes(include=['object']).columns if col not in exclude_columns]\n\n# Define the number of rows and columns for the subplots\nnum_rows = 3  \nnum_cols = (len(column_names) + num_rows - 1) // num_rows\n\n# Create subplots\nfig, axes = plt.subplots(num_rows, num_cols, figsize=(15, 15))\n\n# Flatten the axes for easy iteration\naxes = axes.flatten()\n\n# Loop through each column and create a count plot\nfor i, col in enumerate(column_names):\n    sns.countplot(x=df[col], ax=axes[i])\n    axes[i].set_title(f\"Count plot of {col}\")\n    axes[i].tick_params(axis='x', rotation=90)\n\n# Remove any empty subplots\nfor i in range(len(column_names), num_rows * num_cols):\n    fig.delaxes(axes[i])\n\n# Adjust the layout\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-16T05:50:59.691807Z","iopub.execute_input":"2023-09-16T05:50:59.692186Z","iopub.status.idle":"2023-09-16T05:51:01.759668Z","shell.execute_reply.started":"2023-09-16T05:50:59.692155Z","shell.execute_reply":"2023-09-16T05:51:01.758468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['Postal Code'] = df['Postal Code'].astype(int)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-16T05:56:07.330691Z","iopub.execute_input":"2023-09-16T05:56:07.331142Z","iopub.status.idle":"2023-09-16T05:56:07.356377Z","shell.execute_reply.started":"2023-09-16T05:56:07.331106Z","shell.execute_reply":"2023-09-16T05:56:07.355234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['Order Month'] = df['Order Date'].dt.month\ndf['Order Year'] = df['Order Date'].dt.year\n# Group and sum sales by year\nyearly_sales = df.groupby('Order Year')['Sales'].sum().reset_index()\n\nplt.figure(figsize=(12, 6))\nplt.plot(yearly_sales['Order Year'], yearly_sales['Sales'], marker='o', linestyle='-', color='b')\nplt.title('Yearly Sales Trends')\nplt.xlabel('Year')\nplt.ylabel('Sales')\nplt.grid(True)\nplt.xticks(rotation=45)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-16T06:05:17.584866Z","iopub.execute_input":"2023-09-16T06:05:17.585300Z","iopub.status.idle":"2023-09-16T06:05:17.947619Z","shell.execute_reply.started":"2023-09-16T06:05:17.585268Z","shell.execute_reply":"2023-09-16T06:05:17.946412Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['Month-Year'] = df['Order Date'].dt.strftime('%B %Y')\nmonthly_sales = df.groupby('Month-Year')['Sales'].sum().reset_index()\n\n\n# Plot monthly sales trends with year\nplt.figure(figsize=(12, 6))\nplt.plot(monthly_sales['Month-Year'], monthly_sales['Sales'], marker='o', linestyle='-', color='b')\nplt.title('Monthly Sales Trends with Year')\nplt.xlabel('Month-Year')\nplt.ylabel('Sales')\nplt.grid(True)\nplt.xticks(rotation=45)\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-09-16T06:07:51.552546Z","iopub.execute_input":"2023-09-16T06:07:51.552986Z","iopub.status.idle":"2023-09-16T06:07:52.285096Z","shell.execute_reply.started":"2023-09-16T06:07:51.552950Z","shell.execute_reply":"2023-09-16T06:07:52.283854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Group and sum sales by year and region\nyearly_region_sales = df.groupby(['Order Year', 'Region'])['Sales'].sum().reset_index()\nbest_performing_regions = yearly_region_sales.loc[yearly_region_sales.groupby('Order Year')['Sales'].idxmax()]\nprint(\"The best-performing regions by year are:\")\nprint(best_performing_regions)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-09-16T06:14:53.616411Z","iopub.execute_input":"2023-09-16T06:14:53.616812Z","iopub.status.idle":"2023-09-16T06:14:53.635821Z","shell.execute_reply.started":"2023-09-16T06:14:53.616770Z","shell.execute_reply":"2023-09-16T06:14:53.634623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10, 6))\nplt.bar(df['Order Year'].astype(str) + ' ' + df['Region'], df['Sales'])\nplt.xlabel('Year and Region')\nplt.ylabel('Sales')\nplt.title('Sales by Region for Each Year')\nplt.xticks(rotation=90)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-16T06:22:08.753202Z","iopub.execute_input":"2023-09-16T06:22:08.753576Z","iopub.status.idle":"2023-09-16T06:22:26.548168Z","shell.execute_reply.started":"2023-09-16T06:22:08.753546Z","shell.execute_reply":"2023-09-16T06:22:26.547019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Extract quarter and year\ndf['Order Quarter'] = df['Order Date'].dt.quarter\ndf['Order Year'] = df['Order Date'].dt.year\n# Group and sum sales by quarter and year\nquarterly_sales = df.groupby(['Order Year', 'Order Quarter'])['Sales'].sum().reset_index()\n# Create a new column for Quarter-Year\nquarterly_sales['Quarter-Year'] = 'Q' + quarterly_sales['Order Quarter'].astype(str) + ' ' + quarterly_sales['Order Year'].astype(str)\n# Plot quarterly sales trends with year\nplt.figure(figsize=(12, 6))\nplt.plot(quarterly_sales['Quarter-Year'], quarterly_sales['Sales'], marker='o', linestyle='-', color='b')\nplt.title('Quarterly Sales Trends with Year')\nplt.xlabel('Quarter-Year')\nplt.ylabel('Sales')\nplt.grid(True)\nplt.xticks(rotation=45)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-16T06:23:41.842249Z","iopub.execute_input":"2023-09-16T06:23:41.842650Z","iopub.status.idle":"2023-09-16T06:23:42.153009Z","shell.execute_reply.started":"2023-09-16T06:23:41.842617Z","shell.execute_reply":"2023-09-16T06:23:42.151826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"average_sales_per_mode = df.groupby('Ship Mode')['Sales'].mean()\nprint(\"Average Sales per Order for Each Ship Mode:\")\nprint(average_sales_per_mode)","metadata":{"execution":{"iopub.status.busy":"2023-09-16T06:43:15.549732Z","iopub.execute_input":"2023-09-16T06:43:15.550184Z","iopub.status.idle":"2023-09-16T06:43:15.571255Z","shell.execute_reply.started":"2023-09-16T06:43:15.550151Z","shell.execute_reply":"2023-09-16T06:43:15.569855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a pie chart for average sales per order by ship mode\nplt.figure(figsize=(5,5))\nplt.pie(average_sales_per_mode, labels=average_sales_per_mode.index, autopct='%1.1f%%', startangle=140)\nplt.title('Average Sales per Order for Each Ship Mode')\nplt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-16T06:47:31.793484Z","iopub.execute_input":"2023-09-16T06:47:31.793887Z","iopub.status.idle":"2023-09-16T06:47:31.993699Z","shell.execute_reply.started":"2023-09-16T06:47:31.793856Z","shell.execute_reply":"2023-09-16T06:47:31.992156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"quarterly_segment_sales = df.groupby(['Order Quarter', 'Ship Mode'])['Sales'].sum().unstack(fill_value=0)\n\n# Create a line plot for segment performance on a quarterly basis\nplt.figure(figsize=(12, 6))\nfor segment in quarterly_segment_sales.columns:\n    plt.plot(quarterly_segment_sales.index, quarterly_segment_sales[segment], marker='o', label=segment)\n\nplt.xlabel('Quarter')\nplt.ylabel('Total Sales')\nplt.title('Ship Mode Performance on a Quarterly Basis')\nplt.legend()\nplt.grid(True)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-16T07:13:18.752263Z","iopub.execute_input":"2023-09-16T07:13:18.752689Z","iopub.status.idle":"2023-09-16T07:13:19.151767Z","shell.execute_reply.started":"2023-09-16T07:13:18.752648Z","shell.execute_reply":"2023-09-16T07:13:19.148629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ship_count_by_city = df.groupby(['City', 'Ship Mode']).size().unstack(fill_value=0)\n\ntop_10_cities = ship_count_by_city.sum(axis=1).nlargest(10).index\n\n# Filter the DataFrame to include only the top 10 cities\nship_count_top_10_cities = ship_count_by_city.loc[top_10_cities]\n\n# Create a stacked bar plot to visualize segment preference in the top 10 cities\nship_count_top_10_cities.plot(kind='bar', stacked=True, figsize=(10, 6))\nplt.xlabel('City')\nplt.ylabel('Count')\nplt.title('Ship Mode Preference in Top 10 Cities')\nplt.legend(title='Ship Mode')\nplt.xticks(rotation=45)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-16T07:25:53.474071Z","iopub.execute_input":"2023-09-16T07:25:53.474501Z","iopub.status.idle":"2023-09-16T07:25:53.940527Z","shell.execute_reply.started":"2023-09-16T07:25:53.474468Z","shell.execute_reply":"2023-09-16T07:25:53.939376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pivot_table = pd.crosstab(df['Category'], df['Ship Mode'])\n\n# Create a grouped bar plot\nfig, ax = plt.subplots(figsize=(10, 6))\n\nbar_width = 0.2\nindex = np.arange(len(pivot_table))\n\nfor i, segment in enumerate(pivot_table.columns):\n    ax.bar(\n        index + i * bar_width,\n        pivot_table[segment],\n        bar_width,\n        label=segment\n    )\n\nax.set_xlabel('Category')\nax.set_ylabel('Count')\nax.set_title('Ship Mode Counts Within Each Category')\nax.set_xticks(index + (bar_width * len(pivot_table.columns)) / 2)\nax.set_xticklabels(pivot_table.index)\nax.legend(title='Ship Mode')\n\nplt.xticks(rotation=45)\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-16T07:37:30.599681Z","iopub.execute_input":"2023-09-16T07:37:30.600107Z","iopub.status.idle":"2023-09-16T07:37:31.058364Z","shell.execute_reply.started":"2023-09-16T07:37:30.600075Z","shell.execute_reply":"2023-09-16T07:37:31.057146Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"yearly_segment_sales = df.groupby(['Order Year', 'Segment'])['Sales'].sum().reset_index()\n\n# Find the segment with the highest sales for each year\nbest_segment_by_year = yearly_segment_sales.loc[yearly_segment_sales.groupby('Order Year')['Sales'].idxmax()]\n\nprint(\"Segment with Highest Sales in Each Year:\")\nprint(best_segment_by_year)","metadata":{"execution":{"iopub.status.busy":"2023-09-16T07:02:13.764974Z","iopub.execute_input":"2023-09-16T07:02:13.765387Z","iopub.status.idle":"2023-09-16T07:02:13.786509Z","shell.execute_reply.started":"2023-09-16T07:02:13.765356Z","shell.execute_reply":"2023-09-16T07:02:13.785023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"quarterly_segment_sales = df.groupby(['Order Quarter', 'Segment'])['Sales'].sum().unstack(fill_value=0)\n\n# Create a line plot for segment performance on a quarterly basis\nplt.figure(figsize=(12, 6))\nfor segment in quarterly_segment_sales.columns:\n    plt.plot(quarterly_segment_sales.index, quarterly_segment_sales[segment], marker='o', label=segment)\n\nplt.xlabel('Quarter')\nplt.ylabel('Total Sales')\nplt.title('Segment Performance on a Quarterly Basis')\nplt.legend()\nplt.grid(True)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-16T07:16:18.285631Z","iopub.execute_input":"2023-09-16T07:16:18.286559Z","iopub.status.idle":"2023-09-16T07:16:18.681800Z","shell.execute_reply.started":"2023-09-16T07:16:18.286510Z","shell.execute_reply":"2023-09-16T07:16:18.680628Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"average_sales_by_segment = df.groupby('Segment')['Sales'].mean()\n\n# Create a bar plot for average sales by segment\nplt.figure(figsize=(10, 6))\naverage_sales_by_segment.plot(kind='bar', color='skyblue')\nplt.xlabel('Segment')\nplt.ylabel('Average Sales')\nplt.title('Average Sales in Each Segment')\nplt.xticks(rotation=0)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-16T07:12:21.641574Z","iopub.execute_input":"2023-09-16T07:12:21.642959Z","iopub.status.idle":"2023-09-16T07:12:21.918546Z","shell.execute_reply.started":"2023-09-16T07:12:21.642908Z","shell.execute_reply":"2023-09-16T07:12:21.917395Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"segment_count_by_city = df.groupby(['City', 'Segment']).size().unstack(fill_value=0)\n\ntop_10_cities = segment_count_by_city.sum(axis=1).nlargest(10).index\n\n# Filter the DataFrame to include only the top 10 cities\nsegment_count_top_10_cities = segment_count_by_city.loc[top_10_cities]\n\n# Create a stacked bar plot to visualize segment preference in the top 10 cities\nsegment_count_top_10_cities.plot(kind='bar', stacked=True, figsize=(10, 6))\nplt.xlabel('City')\nplt.ylabel('Count')\nplt.title('Segment Preference in Top 10 Cities')\nplt.legend(title='Segment')\nplt.xticks(rotation=45)\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-09-16T07:20:31.622245Z","iopub.execute_input":"2023-09-16T07:20:31.622668Z","iopub.status.idle":"2023-09-16T07:20:32.065372Z","shell.execute_reply.started":"2023-09-16T07:20:31.622634Z","shell.execute_reply":"2023-09-16T07:20:32.064114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"segment_count_by_state = df.groupby(['State', 'Segment']).size().unstack(fill_value=0)\n\ntop_10_states = segment_count_by_state.sum(axis=1).nlargest(10).index\n\n\nsegment_count_top_10_states = segment_count_by_state.loc[top_10_states]\n\nsegment_count_top_10_states.plot(kind='bar', stacked=True, figsize=(10, 6))\nplt.xlabel('City')\nplt.ylabel('Count')\nplt.title('Segment Preference in Top 10 States')\nplt.legend(title='Segment')\nplt.xticks(rotation=45)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-16T07:23:07.570104Z","iopub.execute_input":"2023-09-16T07:23:07.570483Z","iopub.status.idle":"2023-09-16T07:23:08.099630Z","shell.execute_reply.started":"2023-09-16T07:23:07.570452Z","shell.execute_reply":"2023-09-16T07:23:08.098632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pivot_table = pd.crosstab(df['Category'], df['Segment'])\n\n# Create a grouped bar plot\nfig, ax = plt.subplots(figsize=(10, 6))\n\nbar_width = 0.2\nindex = np.arange(len(pivot_table))\n\nfor i, segment in enumerate(pivot_table.columns):\n    ax.bar(\n        index + i * bar_width,\n        pivot_table[segment],\n        bar_width,\n        label=segment\n    )\n\nax.set_xlabel('Category')\nax.set_ylabel('Count')\nax.set_title('Segment Counts Within Each Category')\nax.set_xticks(index + (bar_width * len(pivot_table.columns)) / 2)\nax.set_xticklabels(pivot_table.index)\nax.legend(title='Segment')\n\nplt.xticks(rotation=45)\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-16T07:35:49.356115Z","iopub.execute_input":"2023-09-16T07:35:49.356514Z","iopub.status.idle":"2023-09-16T07:35:49.792430Z","shell.execute_reply.started":"2023-09-16T07:35:49.356483Z","shell.execute_reply":"2023-09-16T07:35:49.791179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"category_info = df.groupby('Category').agg({\n    'Sub-Category': pd.Series.unique,\n    'Product Name': pd.Series.unique\n}).reset_index()\n\n# Print or display the subcategories and products within each category\nfor index, row in category_info.iterrows():\n    print(f'Category: {row[\"Category\"]}')\n    print('Subcategories:', ', '.join(row[\"Sub-Category\"]))\n    print('Products:', ', '.join(row[\"Product Name\"]))\n    print()","metadata":{"execution":{"iopub.status.busy":"2023-09-16T07:39:15.068017Z","iopub.execute_input":"2023-09-16T07:39:15.068441Z","iopub.status.idle":"2023-09-16T07:39:15.090916Z","shell.execute_reply.started":"2023-09-16T07:39:15.068408Z","shell.execute_reply":"2023-09-16T07:39:15.089827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"top_10_products_by_category = df.groupby('Category').apply(lambda x: x.nlargest(10, 'Sales')).reset_index(drop=True)\n\n# Create a bar plot to visualize the top 10 products in each category\nplt.figure(figsize=(12, 6))\nfor category, data in top_10_products_by_category.groupby('Category'):\n    plt.bar(data['Product Name'], data['Sales'], label=category)\n\nplt.xlabel('Product')\nplt.ylabel('Sales')\nplt.title('Top 10 Products Sold in Each Category')\nplt.xticks(rotation=90)\nplt.legend(title='Category')\nplt.tight_layout()\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-09-16T07:41:56.929198Z","iopub.execute_input":"2023-09-16T07:41:56.929587Z","iopub.status.idle":"2023-09-16T07:41:57.633867Z","shell.execute_reply.started":"2023-09-16T07:41:56.929558Z","shell.execute_reply":"2023-09-16T07:41:57.632905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bottom_10_products_by_category = df.groupby('Category').apply(lambda x: x.nsmallest(10, 'Sales')).reset_index(drop=True)\n\n# Create a bar plot to visualize the bottom 10 products in each category\nplt.figure(figsize=(12, 6))\nfor category, data in bottom_10_products_by_category.groupby('Category'):\n    plt.bar(data['Product Name'], data['Sales'], label=category)\n\nplt.xlabel('Product')\nplt.ylabel('Sales')\nplt.title('Least Performing Products in Each Category')\nplt.xticks(rotation=90)\nplt.legend(title='Category')\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-16T07:43:48.894442Z","iopub.execute_input":"2023-09-16T07:43:48.895442Z","iopub.status.idle":"2023-09-16T07:43:49.522871Z","shell.execute_reply.started":"2023-09-16T07:43:48.895409Z","shell.execute_reply":"2023-09-16T07:43:49.521722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"quarterly_category_sales = df.groupby(['Order Quarter', 'Category'])['Sales'].sum().unstack(fill_value=0)\n\n# Create a line plot for category performance on a quarterly basis\nquarters = df['Order Quarter'].unique()\n\nplt.figure(figsize=(12, 6))\nfor category in quarterly_category_sales.columns:\n    sales = quarterly_category_sales[category]\n    plt.plot(quarters, sales, marker='o', label=category)\n\nplt.xlabel('Quarter')\nplt.ylabel('Total Sales')\nplt.title('Category Performance on a Quarterly Basis')\nplt.legend()\nplt.grid(True)\nplt.xticks(quarters)\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-09-16T07:47:43.829056Z","iopub.execute_input":"2023-09-16T07:47:43.829447Z","iopub.status.idle":"2023-09-16T07:47:44.107381Z","shell.execute_reply.started":"2023-09-16T07:47:43.829418Z","shell.execute_reply":"2023-09-16T07:47:44.106287Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"average_sales_by_category = df.groupby('Category')['Sales'].mean()\n\n# Create a pie chart to visualize the average sales in each category\nplt.figure(figsize=(5,5))\nplt.pie(average_sales_by_category, labels=average_sales_by_category.index, autopct='%1.1f%%', startangle=140)\nplt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n\nplt.title('Average Sales in Each Category')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-16T07:50:07.230922Z","iopub.execute_input":"2023-09-16T07:50:07.231345Z","iopub.status.idle":"2023-09-16T07:50:07.396298Z","shell.execute_reply.started":"2023-09-16T07:50:07.231312Z","shell.execute_reply":"2023-09-16T07:50:07.394596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['Time to Ship'] = (df['Ship Date'] - df['Order Date']).dt.days\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-16T08:02:33.552850Z","iopub.execute_input":"2023-09-16T08:02:33.553244Z","iopub.status.idle":"2023-09-16T08:02:33.584930Z","shell.execute_reply.started":"2023-09-16T08:02:33.553212Z","shell.execute_reply":"2023-09-16T08:02:33.583709Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"correlation = np.corrcoef(df['Time to Ship'], df['Sales'])[0, 1]\n\n# Print the correlation coefficient\nprint(f\"Correlation Coefficient between Time to Ship and Sales: {correlation}\")","metadata":{"execution":{"iopub.status.busy":"2023-09-16T08:02:44.190574Z","iopub.execute_input":"2023-09-16T08:02:44.191339Z","iopub.status.idle":"2023-09-16T08:02:44.199003Z","shell.execute_reply.started":"2023-09-16T08:02:44.191292Z","shell.execute_reply":"2023-09-16T08:02:44.198130Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"A correlation coefficient close to 0 indicates a very weak or almost no linear relationship between the two variables. In this case, the negative sign indicates a very slight negative correlation, which means that as the time to ship increases slightly, sales might decrease slightly, but the relationship is very weak and likely not significant.","metadata":{}},{"cell_type":"code","source":"f_statistic, p_value = stats.f_oneway(\n    df[df['Ship Mode'] == 'Standard Class']['Time to Ship'],\n    df[df['Ship Mode'] == 'Second Class']['Time to Ship'],\n    df[df['Ship Mode'] == 'First Class']['Time to Ship'],\n    df[df['Ship Mode'] == 'Same Day']['Time to Ship']\n)\n\n# Check the p-value to determine if there's a significant relationship\nalpha = 0.05  # Set the significance level\nif p_value < alpha:\n    print(\"There is a significant relationship between Ship Mode and Time to Ship.\")\nelse:\n    print(\"There is no significant relationship between Ship Mode and Time to Ship.\")","metadata":{"execution":{"iopub.status.busy":"2023-09-16T08:05:54.671274Z","iopub.execute_input":"2023-09-16T08:05:54.671655Z","iopub.status.idle":"2023-09-16T08:05:54.698945Z","shell.execute_reply.started":"2023-09-16T08:05:54.671627Z","shell.execute_reply":"2023-09-16T08:05:54.698139Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from statsmodels.stats.multicomp import pairwise_tukeyhsd\n\n# Perform Tukey HSD test\ntukey_result = pairwise_tukeyhsd(df['Time to Ship'], df['Ship Mode'])\n\n# Print the results\nprint(tukey_result)","metadata":{"execution":{"iopub.status.busy":"2023-09-16T08:18:33.570850Z","iopub.execute_input":"2023-09-16T08:18:33.571252Z","iopub.status.idle":"2023-09-16T08:18:34.019508Z","shell.execute_reply.started":"2023-09-16T08:18:33.571222Z","shell.execute_reply":"2023-09-16T08:18:34.018296Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here are the key findings:\n\nThere are significant differences in \"Time to Ship\" between all pairs of ship modes. All comparisons have p-adj values less than 0.05, indicating that the mean times to ship are significantly different between these ship modes.\n\nSpecifically, \"Same Day\" and \"Standard Class\" have the largest mean difference in \"Time to Ship\" (\"meandiff\" = 4.9638), and all comparisons involving these two ship modes are significant.\n\n\"First Class\" and \"Second Class\" also have a significant difference in \"Time to Ship\" (\"meandiff\" = 1.07).\n\nIn summary, the Tukey HSD test reveals that there are significant differences in the mean times to ship between all pairs of ship modes. These differences indicate that the choice of ship mode is associated with variations in the time it takes to ship orders, and all of the differences are statistically significant.","metadata":{}},{"cell_type":"code","source":"f_statistic, p_value = stats.f_oneway(\n    df[df['Segment'] == 'Consumer']['Time to Ship'],\n    df[df['Segment'] == 'Corporate']['Time to Ship'],\n    df[df['Segment'] == 'Home Office']['Time to Ship']\n)\n\n# Check the p-value to determine if there's a significant relationship\nalpha = 0.05  # Set the significance level\nif p_value < alpha:\n    print(\"There is a significant relationship between Segment and Time to Ship.\")\nelse:\n    print(\"There is no significant relationship between Segment and Time to Ship.\")\n","metadata":{"execution":{"iopub.status.busy":"2023-09-16T08:08:58.694952Z","iopub.execute_input":"2023-09-16T08:08:58.695350Z","iopub.status.idle":"2023-09-16T08:08:58.720957Z","shell.execute_reply.started":"2023-09-16T08:08:58.695321Z","shell.execute_reply":"2023-09-16T08:08:58.719749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f_statistic, p_value = stats.f_oneway(\n    df[df['Region'] == 'East']['Time to Ship'],\n    df[df['Region'] == 'West']['Time to Ship'],\n    df[df['Region'] == 'Central']['Time to Ship'],\n    df[df['Region'] == 'South']['Time to Ship']\n)\n\n# Check the p-value to determine if there's a significant relationship\nalpha = 0.05  # Set the significance level\nif p_value < alpha:\n    print(\"There is a significant relationship between Region and Time to Ship.\")\nelse:\n    print(\"There is no significant relationship between Region and Time to Ship.\")","metadata":{"execution":{"iopub.status.busy":"2023-09-16T08:12:01.890393Z","iopub.execute_input":"2023-09-16T08:12:01.890809Z","iopub.status.idle":"2023-09-16T08:12:01.917400Z","shell.execute_reply.started":"2023-09-16T08:12:01.890762Z","shell.execute_reply":"2023-09-16T08:12:01.916513Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from statsmodels.stats.multicomp import pairwise_tukeyhsd\n\n# Perform Tukey HSD test\ntukey_result = pairwise_tukeyhsd(df['Time to Ship'], df['Region'])\n\n# Print the results\nprint(tukey_result)","metadata":{"execution":{"iopub.status.busy":"2023-09-16T08:15:35.239592Z","iopub.execute_input":"2023-09-16T08:15:35.240394Z","iopub.status.idle":"2023-09-16T08:15:35.707056Z","shell.execute_reply.started":"2023-09-16T08:15:35.240354Z","shell.execute_reply":"2023-09-16T08:15:35.705665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The results of the Tukey HSD test for multiple comparisons of means between different regions and their respective \"Time to Ship\" values are as follows:\n\nThere are three regions: Central, East, and West.\nThe test compares the means of \"Time to Ship\" between these regions.\nThe \"meandiff\" column represents the mean difference in \"Time to Ship\" between the compared regions.\nThe \"p-adj\" column represents the adjusted p-value for each comparison.\nThe \"lower\" and \"upper\" columns represent the lower and upper bounds of the confidence interval for the mean difference.\nThe \"reject\" column indicates whether to reject the null hypothesis (True) or not (False) for each comparison.\nHere are the key findings:\n\nThere is a significant difference in \"Time to Ship\" between the Central and East regions, with the East region having a shorter time to ship (\"meandiff\" = -0.1556, p-adj < 0.05).\n\nThere is a significant difference in \"Time to Ship\" between the Central and West regions, with the West region having a shorter time to ship (\"meandiff\" = -0.1356, p-adj < 0.05).\n\nThere is no significant difference in \"Time to Ship\" between the East and South regions (\"meandiff\" = 0.051, p-adj > 0.05).\n\nThere is no significant difference in \"Time to Ship\" between the East and West regions (\"meandiff\" = 0.02, p-adj > 0.05).\n\nThere is no significant difference in \"Time to Ship\" between the South and West regions (\"meandiff\" = -0.0309, p-adj > 0.05).\n\nIn summary, the Tukey HSD test reveals that the Central and East regions have significantly shorter times to ship compared to the Central and West regions. However, there are no significant differences in time to ship between the East and South regions, East and West regions, and South and West regions. The \"reject\" column indicates whether the differences are statistically significant at the chosen significance level (FWER=0.05), with \"True\" indicating significance.","metadata":{}},{"cell_type":"code","source":"max_time_to_ship_by_city_product = df.groupby(['City', 'Product Name'])['Time to Ship'].max().reset_index()\n\n# Find the combination(s) with the maximum time to ship\nmax_time_to_ship = max_time_to_ship_by_city_product['Time to Ship'].max()\n\n# Filter the DataFrame to include only the rows with the maximum time to ship\nmax_time_to_ship_data = max_time_to_ship_by_city_product[max_time_to_ship_by_city_product['Time to Ship'] == max_time_to_ship]\n\n# Display the product names and cities where the time to ship is maximum\nprint(max_time_to_ship_data[['City', 'Product Name']])","metadata":{"execution":{"iopub.status.busy":"2023-09-16T08:20:56.547426Z","iopub.execute_input":"2023-09-16T08:20:56.548008Z","iopub.status.idle":"2023-09-16T08:20:56.574024Z","shell.execute_reply.started":"2023-09-16T08:20:56.547971Z","shell.execute_reply":"2023-09-16T08:20:56.572909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_time_to_ship_data = df[df['Time to Ship'] == max_time_to_ship]\n\n# Create a bar chart to visualize the results\nplt.figure(figsize=(10, 6))\nplt.bar(max_time_to_ship_data['State'], max_time_to_ship_data['Time to Ship'], color='skyblue')\nplt.xlabel('State')\nplt.ylabel('Time to Ship')\nplt.title('States with Maximum Time to Ship by Product')\nplt.xticks(rotation=90)  # Rotate x-axis labels for better readability\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-16T08:23:31.839087Z","iopub.execute_input":"2023-09-16T08:23:31.839530Z","iopub.status.idle":"2023-09-16T08:23:33.487744Z","shell.execute_reply.started":"2023-09-16T08:23:31.839498Z","shell.execute_reply":"2023-09-16T08:23:33.486667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"average_time_to_ship_by_city = df.groupby('City')['Time to Ship'].mean().reset_index()\n\n# Sort the cities in ascending order of average time to ship\nsorted_cities = average_time_to_ship_by_city.sort_values(by='Time to Ship')\n\n# Select the top 10 cities with the shortest shipping times\ntop_10_cities = sorted_cities.head(10)\n\n# Display the top 10 cities with the shortest shipping times\nprint(top_10_cities)","metadata":{"execution":{"iopub.status.busy":"2023-09-16T08:24:37.005548Z","iopub.execute_input":"2023-09-16T08:24:37.006769Z","iopub.status.idle":"2023-09-16T08:24:37.020655Z","shell.execute_reply.started":"2023-09-16T08:24:37.006730Z","shell.execute_reply":"2023-09-16T08:24:37.019487Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Create a bar chart to visualize the results\nplt.figure(figsize=(12, 6))\nplt.barh(top_10_cities['City'], top_10_cities['Time to Ship'], color='skyblue')\nplt.xlabel('Average Time to Ship')\nplt.ylabel('City')\nplt.title('Top 10 Cities with Shortest Average Time to Ship')\nplt.gca().invert_yaxis()  # Invert the y-axis to display the shortest times at the top\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-16T08:34:55.431101Z","iopub.execute_input":"2023-09-16T08:34:55.431495Z","iopub.status.idle":"2023-09-16T08:34:55.864980Z","shell.execute_reply.started":"2023-09-16T08:34:55.431467Z","shell.execute_reply":"2023-09-16T08:34:55.863839Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"average_time_to_ship_by_state = df.groupby('State')['Time to Ship'].mean().reset_index()\nplt.figure(figsize=(10, 6))\nplt.bar(average_time_to_ship_by_state['State'], average_time_to_ship_by_state['Time to Ship'], color='skyblue')\nplt.xlabel('State')\nplt.ylabel('Average Time to Ship')\nplt.title('Average Time to Ship by State')\nplt.xticks(rotation=90)  # Rotate x-axis labels for better readability\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-16T08:31:24.237631Z","iopub.execute_input":"2023-09-16T08:31:24.238037Z","iopub.status.idle":"2023-09-16T08:31:25.005496Z","shell.execute_reply.started":"2023-09-16T08:31:24.238006Z","shell.execute_reply":"2023-09-16T08:31:25.004390Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"average_time_to_ship_by_category = df.groupby('Category')['Time to Ship'].mean().reset_index()\nplt.figure(figsize=(10, 6))\nplt.bar(average_time_to_ship_by_category['Category'], average_time_to_ship_by_category['Time to Ship'], color='skyblue')\nplt.xlabel('Category')\nplt.ylabel('Time to Ship (Days)')\nplt.title('Average Time to Ship for Each Category')\nplt.xticks(rotation=45)\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-16T08:34:02.311288Z","iopub.execute_input":"2023-09-16T08:34:02.312485Z","iopub.status.idle":"2023-09-16T08:34:02.697033Z","shell.execute_reply.started":"2023-09-16T08:34:02.312444Z","shell.execute_reply":"2023-09-16T08:34:02.696205Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sales_by_subcategory_quarter = df.groupby(['Sub-Category', 'Order Quarter'])['Sales'].sum().reset_index()\n\n# Pivot the data to have subcategories as columns and quarters as rows\npivot_sales = sales_by_subcategory_quarter.pivot(index='Order Quarter', columns='Sub-Category', values='Sales')\n\n# Plot the results as a bar chart\npivot_sales.plot(kind='bar', figsize=(10, 6))\nplt.xlabel('Quarter')\nplt.ylabel('Sales')\nplt.title('Sales of Subcategories in Each Quarter')\nplt.xticks(rotation=45)\nplt.legend(title='Subcategory')\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-16T08:37:23.147285Z","iopub.execute_input":"2023-09-16T08:37:23.147661Z","iopub.status.idle":"2023-09-16T08:37:23.906470Z","shell.execute_reply.started":"2023-09-16T08:37:23.147628Z","shell.execute_reply":"2023-09-16T08:37:23.905091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# 2. Customer Segmentation\n# Segment customers by 'Segment'\nsegmented_customers = df['Segment'].value_counts()\nplt.figure(figsize=(8, 6))\nsns.barplot(x=segmented_customers.index, y=segmented_customers.values)\nplt.title('Customer Segmentation')\nplt.xlabel('Segment')\nplt.ylabel('Number of Customers')\nplt.show()\n\n# 3. Customer Demographics Analysis\n# Analyze customer demographics (e.g., region, state, city)\nregion_distribution = df['Region'].value_counts()\nstate_distribution = df['State'].value_counts()\ncity_distribution = df['City'].value_counts()\n\n# 4. Customer Purchase Behavior Analysis\n# Calculate metrics like average order value and total revenue\naverage_order_value = df.groupby('Customer ID')['Sales'].mean()\ntotal_revenue = df.groupby('Customer ID')['Sales'].sum()\nprint(total_revenue)\n# 5. Customer Segmentation Insights\n# Develop customer profiles for each segment\nsegment_profiles = df.groupby('Segment')['Sales'].describe()\nprint(segment_profiles)\n# 6. Customer Retention Analysis\n# Calculate customer retention rates\nretention_rates = df.groupby(['Customer ID', 'Order Date']).size().reset_index(name='Order Count')\nretention_rates = retention_rates.groupby('Customer ID').count()\nchurn_rate = (1 - (retention_rates[retention_rates['Order Date'] > 1].shape[0] / df['Customer ID'].nunique())) * 100\nprint(churn_rate)\n# 7. Cross-Selling and Upselling Opportunities\n# Analyze which products are frequently purchased together\ncross_sell_matrix = df.pivot_table(index='Order ID', columns='Product Name', values='Sales', aggfunc='sum', fill_value=0)\nprint(cross_sell_matrix)\n# 8. Geographical Insights\n# Determine geographic distribution of customers\nplt.figure(figsize=(10, 5))\nsns.countplot(data=df, x='Region')\nplt.title('Customer Distribution by Region')\nplt.xlabel('Region')\nplt.ylabel('Number of Customers')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-16T10:06:47.778155Z","iopub.execute_input":"2023-09-16T10:06:47.779300Z","iopub.status.idle":"2023-09-16T10:06:49.083385Z","shell.execute_reply.started":"2023-09-16T10:06:47.779256Z","shell.execute_reply":"2023-09-16T10:06:49.082215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This is a relatively low churn rate, indicating good customer retention for the superstore. It's important to continue monitoring and engaging with customers to maintain or improve this retention rate.","metadata":{}},{"cell_type":"code","source":"# Calculate total sales revenue\ntotal_sales = df['Sales'].sum()\n\n# Calculate total number of orders\ntotal_orders = df['Order ID'].nunique()\n\n# Calculate average purchase value\naverage_purchase_value = total_sales / total_orders\n# Calculate total number of unique customers\ntotal_customers = df['Customer ID'].nunique()\n\n# Calculate average purchase frequency\naverage_purchase_frequency = total_orders / total_customers\ncustomer_lifespan = 1 / churn_rate\nCLV = average_purchase_value * average_purchase_frequency * customer_lifespan\nCLV","metadata":{"execution":{"iopub.status.busy":"2023-09-16T10:13:18.540905Z","iopub.execute_input":"2023-09-16T10:13:18.541308Z","iopub.status.idle":"2023-09-16T10:13:18.554948Z","shell.execute_reply.started":"2023-09-16T10:13:18.541279Z","shell.execute_reply":"2023-09-16T10:13:18.553965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This means that, on average, a customer is expected to generate around $1,739.64 in revenue over the one-year CLV period.","metadata":{}},{"cell_type":"code","source":"N = 10  # You can change this value to show more or fewer products\nproduct_performance = df.groupby('Product ID').agg({\n    'Product Name': 'first',\n    'Sales': 'sum',\n}).reset_index()\nbest_selling_products = product_performance.sort_values(by='Sales', ascending=False)\nleast_selling_products = product_performance.sort_values(by='Sales')\n\n# Select the top N best-selling products and their sales values\ntop_best_selling = best_selling_products.head(N)\ntop_best_selling_names = top_best_selling['Product Name']\ntop_best_selling_sales = top_best_selling['Sales']\n\n# Select the top N least-selling products and their sales values\ntop_least_selling = least_selling_products.head(N)\ntop_least_selling_names = top_least_selling['Product Name']\ntop_least_selling_sales = top_least_selling['Sales']\n\n# Create subplots for best-selling and least-selling products\nplt.figure(figsize=(12, 6))\n\n# Subplot for best-selling products\nplt.subplot(1, 2, 1)\nplt.barh(top_best_selling_names, top_best_selling_sales, color='skyblue')\nplt.xlabel('Total Sales')\nplt.title(f'Top {N} Best-Selling Products')\nplt.gca().invert_yaxis()  # Invert the y-axis to show the top products at the top\n\n# Subplot for least-selling products\nplt.subplot(1, 2, 2)\nplt.barh(top_least_selling_names, top_least_selling_sales, color='salmon')\nplt.xlabel('Total Sales')\nplt.title(f'Top {N} Least-Selling Products')\nplt.gca().invert_yaxis()  # Invert the y-axis to show the top products at the top\n\n# Adjust spacing between subplots\nplt.tight_layout()\n\n# Display the plot\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-16T10:18:48.851933Z","iopub.execute_input":"2023-09-16T10:18:48.852344Z","iopub.status.idle":"2023-09-16T10:18:49.553875Z","shell.execute_reply.started":"2023-09-16T10:18:48.852312Z","shell.execute_reply":"2023-09-16T10:18:49.552445Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.cluster import KMeans\nimport matplotlib.pyplot as plt\nimport warnings\n\n# Assuming you have a DataFrame 'df' with 'Customer ID,' 'Order Frequency,' and other relevant features\n# Assuming you have a DataFrame called 'df' with 'Customer ID' and 'Order Date' columns\n# Convert 'Order Date' to a datetime format if it's not already in one\ndf['Order Date'] = pd.to_datetime(df['Order Date'])\n\n# Group the data by 'Customer ID' and count the number of unique orders\norder_frequency = df.groupby('Customer ID')['Order Date'].nunique().reset_index()\n\n# Rename the column to 'Order Frequency'\norder_frequency = order_frequency.rename(columns={'Order Date': 'Order Frequency'})\n\n# Merge the calculated order frequency back into the main DataFrame\ndf = df.merge(order_frequency, on='Customer ID', how='left', suffixes=('', '_freq'))\n\n\n# Select the features you want to use for clustering (e.g., 'Order Frequency' and 'Sales')\nX = df[['Order Frequency', 'Sales']]\n\n# Choose the number of clusters (you can experiment with different values)\nnum_clusters = 3\n\n# Initialize the K-Means model with n_init set explicitly to suppress the warning\nkmeans = KMeans(n_clusters=num_clusters, random_state=0, n_init=10)\n\n# Fit the model to your data\nkmeans.fit(X)\n\n# Add the cluster labels back to your DataFrame\ndf['Cluster'] = kmeans.labels_\n\n# Visualize the clusters\nplt.figure(figsize=(10, 6))\nscatter = plt.scatter(df['Order Frequency'], df['Sales'], c=df['Cluster'], cmap='rainbow')\nplt.xlabel('Order Frequency')\nplt.ylabel('Sales')\nplt.title('Customer Segmentation')\n# Get unique cluster labels\nunique_labels = df['Cluster'].unique()\n\n# Create a legend with the cluster labels\nlegend_labels = ['Cluster ' + str(label) for label in unique_labels]\nplt.legend(handles=scatter.legend_elements()[0], labels=legend_labels)\n\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-09-16T10:48:43.193137Z","iopub.execute_input":"2023-09-16T10:48:43.193536Z","iopub.status.idle":"2023-09-16T10:48:45.174584Z","shell.execute_reply.started":"2023-09-16T10:48:43.193506Z","shell.execute_reply":"2023-09-16T10:48:45.173756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculate cluster statistics\ncluster_stats = df.groupby('Cluster')[['Order Frequency', 'Sales']].mean().reset_index()\n\n# Add cluster size\ncluster_size = df['Cluster'].value_counts().reset_index()\ncluster_size.columns = ['Cluster', 'Count']\ncluster_stats = cluster_stats.merge(cluster_size, on='Cluster')\n\n# Define cluster labels\ncluster_labels = {\n    0: 'High Frequency, High Sales',\n    1: 'Low Frequency, Low Sales',\n    2: 'Medium Frequency, Medium Sales'\n}\n\n# Add cluster labels\ncluster_stats['Cluster Label'] = cluster_stats['Cluster'].map(cluster_labels)\n\n# Create a tabloid or table\ncluster_stats_tabloid = cluster_stats[['Cluster', 'Cluster Label', 'Order Frequency', 'Sales', 'Count']]\n\n# Display the tabloid\ncluster_stats_tabloid\n","metadata":{"execution":{"iopub.status.busy":"2023-09-16T10:50:40.964651Z","iopub.execute_input":"2023-09-16T10:50:40.965107Z","iopub.status.idle":"2023-09-16T10:50:40.992302Z","shell.execute_reply.started":"2023-09-16T10:50:40.965071Z","shell.execute_reply":"2023-09-16T10:50:40.991149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Based on the K-Means clustering analysis of customer data, we have identified three distinct customer segments:\n\nCluster 0 - High Frequency, High Sales:\n\nCustomers in this segment have a high order frequency (approximately 7.21 orders) and high sales (approximately $134.54).\nThis cluster is the largest, containing 9,305 customers.\nCluster 1 - Low Frequency, Low Sales:\n\nCustomers in this segment have a low order frequency (approximately 6.33 orders) and low sales (approximately $10,608.89).\nThis cluster is the smallest, with only 15 customers.\nCluster 2 - Medium Frequency, Medium Sales:\n\nCustomers in this segment exhibit medium order frequency (approximately 7.19 orders) and medium sales (approximately $1,771.95).\nThis cluster includes 480 customers.\nThese findings provide valuable insights into the different customer behaviors within the dataset. For instance:\n\nCluster 0 represents a large group of customers who frequently make purchases with relatively high sales. These customers are likely loyal and contribute significantly to revenue.\n\nCluster 1 includes a small group of customers who make infrequent and low-value purchases. It may be essential to engage with this segment to increase their activity or explore reasons for their limited engagement.\n\nCluster 2 comprises customers with moderate purchase frequency and spending. Understanding their needs and preferences can help tailor marketing strategies.\n\nOverall, these customer segments allow for more targeted marketing, product recommendations, and customer retention efforts, ultimately contributing to business growth and optimization.","metadata":{}},{"cell_type":"code","source":"df1 = pd.read_csv(\"/kaggle/input/sales-forecasting/train.csv\",index_col = 0)\ndf1['Postal Code'] = df1['Postal Code'].fillna(5401).astype('int')\ndf1.drop(['Order ID','Customer ID','Customer Name','Product ID'],axis = 1, inplace = True)","metadata":{"execution":{"iopub.status.busy":"2023-09-16T11:00:45.917682Z","iopub.execute_input":"2023-09-16T11:00:45.918132Z","iopub.status.idle":"2023-09-16T11:00:45.985396Z","shell.execute_reply.started":"2023-09-16T11:00:45.918090Z","shell.execute_reply":"2023-09-16T11:00:45.984273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-16T11:00:49.021070Z","iopub.execute_input":"2023-09-16T11:00:49.021491Z","iopub.status.idle":"2023-09-16T11:00:49.043337Z","shell.execute_reply.started":"2023-09-16T11:00:49.021457Z","shell.execute_reply":"2023-09-16T11:00:49.042144Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import mean_squared_error\n\n# Assuming 'df1' is your DataFrame with label-encoded categorical columns\nnon_numerical_columns = df1.select_dtypes(exclude=['number']).columns\n\n# Initialize a LabelEncoder\nlabel_encoder = LabelEncoder()\n\n# Encode non-numerical columns\nfor column in non_numerical_columns:\n    df1[column + '_Encoded'] = label_encoder.fit_transform(df1[column])\n    df1.drop(column, axis=1, inplace=True)\ndf1.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-16T11:03:16.650605Z","iopub.execute_input":"2023-09-16T11:03:16.651046Z","iopub.status.idle":"2023-09-16T11:03:16.759206Z","shell.execute_reply.started":"2023-09-16T11:03:16.651013Z","shell.execute_reply":"2023-09-16T11:03:16.757960Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from xgboost import XGBRegressor\n# Define your features and target variable\nX = df1.drop(columns=['Sales'])  # Features\ny = df1['Sales']  # Target variable\n\n# Split the data into training and testing sets (e.g., 80% training, 20% testing)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nxgb_model = XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=3)\nxgb_model.fit(X_train, y_train)\n\n# Make predictions on the test set\ny_pred = xgb_model.predict(X_test)\n\n# Calculate Mean Squared Error (MSE) as the evaluation metric\nmse = mean_squared_error(y_test, y_pred)\nprint(\"Mean Squared Error:\", mse)","metadata":{"execution":{"iopub.status.busy":"2023-09-16T11:23:22.060871Z","iopub.execute_input":"2023-09-16T11:23:22.061274Z","iopub.status.idle":"2023-09-16T11:23:22.561354Z","shell.execute_reply.started":"2023-09-16T11:23:22.061243Z","shell.execute_reply":"2023-09-16T11:23:22.560479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}